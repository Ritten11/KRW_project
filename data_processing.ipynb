{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import rdflib\n",
    "from rdflib import URIRef\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:23:49.258961Z",
     "end_time": "2023-04-11T17:23:49.316111Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cleaning NCIT ontology"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A4 --> occurrences: 1\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P378 --> occurrences: 1\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A12 --> occurrences: 10\n",
      "property: http://www.w3.org/2000/01/rdf-schema#subPropertyOf --> occurrences: 11\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A3 --> occurrences: 11\n",
      "property: http://www.w3.org/2002/07/owl#oneOf --> occurrences: 19\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A9 --> occurrences: 28\n",
      "property: http://www.w3.org/2000/01/rdf-schema#domain --> occurrences: 86\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A2 --> occurrences: 97\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A1 --> occurrences: 97\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A14 --> occurrences: 105\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A30 --> occurrences: 124\n",
      "property: http://www.w3.org/2002/07/owl#unionOf --> occurrences: 150\n",
      "property: http://www.w3.org/2000/01/rdf-schema#range --> occurrences: 151\n",
      "property: http://www.w3.org/2002/07/owl#disjointWith --> occurrences: 171\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A27 --> occurrences: 182\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A16 --> occurrences: 201\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A35 --> occurrences: 320\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A36 --> occurrences: 330\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A23 --> occurrences: 364\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A25 --> occurrences: 397\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A33 --> occurrences: 431\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A34 --> occurrences: 446\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A21 --> occurrences: 522\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A22 --> occurrences: 539\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A20 --> occurrences: 550\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A19 --> occurrences: 564\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A24 --> occurrences: 610\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A18 --> occurrences: 614\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A26 --> occurrences: 636\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A17 --> occurrences: 638\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A28 --> occurrences: 663\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A42 --> occurrences: 725\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A29 --> occurrences: 756\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A37 --> occurrences: 760\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A48 --> occurrences: 781\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A39 --> occurrences: 799\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A38 --> occurrences: 809\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A40 --> occurrences: 1059\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P361 --> occurrences: 1202\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P398 --> occurrences: 1268\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P317 --> occurrences: 1692\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A5 --> occurrences: 1864\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A6 --> occurrences: 1873\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P372 --> occurrences: 2222\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A15 --> occurrences: 4048\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A13 --> occurrences: 4162\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A7 --> occurrences: 4679\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P310 --> occurrences: 8526\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P363 --> occurrences: 13273\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A31 --> occurrences: 14118\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A32 --> occurrences: 14134\n",
      "property: http://www.w3.org/2002/07/owl#equivalentClass --> occurrences: 20017\n",
      "property: http://www.w3.org/2002/07/owl#intersectionOf --> occurrences: 20303\n",
      "property: http://www.w3.org/1999/02/22-rdf-syntax-ns#rest --> occurrences: 111989\n",
      "property: http://www.w3.org/1999/02/22-rdf-syntax-ns#first --> occurrences: 111989\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P322 --> occurrences: 122308\n",
      "property: http://www.w3.org/2002/07/owl#onProperty --> occurrences: 133333\n",
      "property: http://www.w3.org/2002/07/owl#someValuesFrom --> occurrences: 133333\n",
      "property: http://data.bioontology.org/metadata/prefixIRI --> occurrences: 178721\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#P106 --> occurrences: 188927\n",
      "property: http://www.w3.org/2000/01/rdf-schema#subClassOf --> occurrences: 258855\n",
      "property: http://www.w3.org/1999/02/22-rdf-syntax-ns#type --> occurrences: 333132\n",
      "property: http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A8 --> occurrences: 345099\n"
     ]
    }
   ],
   "source": [
    "ncit = rdflib.Graph()\n",
    "ncit.parse(\"./data/semi_cleaned_NCIT.rdf\",format='xml') #Load the ontology with all datatype properties already removed\n",
    "\n",
    "properties = list(ncit.query(\n",
    "    'SELECT ?p (COUNT(?o) as ?occurrences) WHERE { ?s ?p ?o. } GROUP BY ?p ORDER BY ?occurrences'\n",
    "))\n",
    "for p in properties: # list all the remaining\n",
    "    print(f'property: {p[0].toPython()} --> occurrences: {p[1].toPython()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T18:06:04.520119Z",
     "end_time": "2023-04-10T18:09:03.559981Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdflib.term.URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf'),\n",
      " rdflib.term.Literal('258855', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#integer')))\n",
      "(rdflib.term.URIRef('http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#A8'),\n",
      " rdflib.term.Literal('345099', datatype=rdflib.term.URIRef('http://www.w3.org/2001/XMLSchema#integer')))\n"
     ]
    }
   ],
   "source": [
    "# For now, we are only interested in the rdfs:subClassOf relation and ncit:A8, which has the 'Concept_In_Subset' label\n",
    "\n",
    "pprint(properties[-3])\n",
    "pprint(properties[-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205453\n"
     ]
    }
   ],
   "source": [
    "# extract the taxonomy structure from the semi-cleaned ontology. Making sure to exclude all blank nodes\n",
    "\n",
    "query = f'CONSTRUCT {{?s1 <{properties[-3][0]}> ?o1 .}} WHERE {{ ?s1 <{properties[-3][0]}> ?o1. FILTER isIRI(?o1) FILTER isIRI(?s1)}} '\n",
    "\n",
    "taxonomy = ncit.query(\n",
    "    query\n",
    ")\n",
    "\n",
    "print(len(taxonomy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345099\n"
     ]
    }
   ],
   "source": [
    "# extract the subset structure from the semi-cleaned ontology. Making sure to exclude all blank nodes\n",
    "\n",
    "query = f'CONSTRUCT {{?s1 <{properties[-1][0]}> ?o1 .}} WHERE {{ ?s1 <{properties[-1][0]}> ?o1. FILTER isIRI(?o1) FILTER isIRI(?s1)}} '\n",
    "\n",
    "subset = ncit.query(\n",
    "    query\n",
    ")\n",
    "\n",
    "print(len(subset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# combine the taxonomy and the subset structure into a new graph.\n",
    "\n",
    "tax_and_subset_KG = rdflib.Graph()\n",
    "\n",
    "for t in list(taxonomy):\n",
    "    tax_and_subset_KG.add(t)\n",
    "\n",
    "# At this point only the taxonomy is stored within the graph\n",
    "tax_and_subset_KG.serialize('./data/tax_NCIT.ttl', format='ttl')\n",
    "\n",
    "for t in list(subset):\n",
    "    tax_and_subset_KG.add(t)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=Nffaac6ca329c467bbf20bd70202950a1 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the graph for later usage\n",
    "\n",
    "tax_and_subset_KG.serialize('./data/tax_and_subset_NCIT.ttl', format='ttl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603954\n"
     ]
    }
   ],
   "source": [
    "# verifying that the graph has been saved correctly\n",
    "\n",
    "tax_sub_NCIT = rdflib.Graph()\n",
    "tax_sub_NCIT.parse(\"./data/tax_and_subset_NCIT.ttl\",format='ttl')\n",
    "\n",
    "print(len(tax_sub_NCIT))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=Na5f7f55ce9d14a748e307bfc34d8e625 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tax_sub_NCIT.serialize(\"./data/tax_and_subset_NCIT.owl\", format='xml')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# A function for determining the max depth of the ontology. It also shows the top node, which is needed further down the line\n",
    "\n",
    "def find_max_taxonomy_level(g):\n",
    "    print(f'current size graph: {len(g)}')\n",
    "    if len(g) == 1:\n",
    "        for t in g:\n",
    "            print('found top node: ')\n",
    "            pprint(t[2])\n",
    "        return 0\n",
    "    else:\n",
    "        subClass = URIRef('http://www.w3.org/2000/01/rdf-schema#subClassOf')\n",
    "        query = f'CONSTRUCT {{?o <{subClass}> ?o2}} WHERE {{ ?s <{subClass}> ?o. ?o <{subClass}> ?o2 . }}'\n",
    "        rest_g = list(g.query(\n",
    "            query\n",
    "        ))\n",
    "        new_g = rdflib.Graph()\n",
    "        for t in rest_g:\n",
    "            new_g.add(t)\n",
    "        return 1 + find_max_taxonomy_level(new_g)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T20:52:12.523256Z",
     "end_time": "2023-04-06T20:52:12.527790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current size graph: 205453\n",
      "current size graph: 39718\n",
      "current size graph: 13164\n",
      "current size graph: 6393\n",
      "current size graph: 3397\n",
      "current size graph: 1853\n",
      "current size graph: 1053\n",
      "current size graph: 604\n",
      "current size graph: 365\n",
      "current size graph: 221\n",
      "current size graph: 127\n",
      "current size graph: 72\n",
      "current size graph: 42\n",
      "current size graph: 26\n",
      "current size graph: 17\n",
      "current size graph: 11\n",
      "current size graph: 8\n",
      "current size graph: 6\n",
      "current size graph: 4\n",
      "current size graph: 3\n",
      "current size graph: 2\n",
      "current size graph: 1\n",
      "found top node: \n",
      "rdflib.term.URIRef('http://www.w3.org/2002/07/owl#Thing')\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# Run the find depth function on the bare taxonomy\n",
    "\n",
    "g = rdflib.Graph()\n",
    "g.parse(\"./data/tax_NCIT.ttl\")\n",
    "\n",
    "max_level = find_max_taxonomy_level(g)\n",
    "print(max_level)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-06T20:52:15.200866Z",
     "end_time": "2023-04-06T20:52:52.282194Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Determing the nodes at different ranks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "currently at rank: 0, analyzing 1 nodes. Remaining size taxonomy: 205453\n",
      "currently at rank: 1, analyzing 19 nodes. Remaining size taxonomy: 205434\n",
      "currently at rank: 2, analyzing 776 nodes. Remaining size taxonomy: 204658\n",
      "currently at rank: 3, analyzing 13154 nodes. Remaining size taxonomy: 191457\n",
      "currently at rank: 4, analyzing 23698 nodes. Remaining size taxonomy: 166918\n",
      "currently at rank: 5, analyzing 38164 nodes. Remaining size taxonomy: 127037\n",
      "currently at rank: 6, analyzing 29814 nodes. Remaining size taxonomy: 94823\n",
      "currently at rank: 7, analyzing 22939 nodes. Remaining size taxonomy: 70430\n",
      "currently at rank: 8, analyzing 21440 nodes. Remaining size taxonomy: 47095\n",
      "currently at rank: 9, analyzing 28933 nodes. Remaining size taxonomy: 15452\n",
      "currently at rank: 10, analyzing 8374 nodes. Remaining size taxonomy: 5710\n",
      "currently at rank: 11, analyzing 3545 nodes. Remaining size taxonomy: 1628\n",
      "currently at rank: 12, analyzing 1118 nodes. Remaining size taxonomy: 326\n",
      "currently at rank: 13, analyzing 233 nodes. Remaining size taxonomy: 86\n",
      "currently at rank: 14, analyzing 41 nodes. Remaining size taxonomy: 44\n",
      "currently at rank: 15, analyzing 20 nodes. Remaining size taxonomy: 24\n",
      "currently at rank: 16, analyzing 11 nodes. Remaining size taxonomy: 13\n",
      "currently at rank: 17, analyzing 6 nodes. Remaining size taxonomy: 7\n",
      "currently at rank: 18, analyzing 4 nodes. Remaining size taxonomy: 3\n",
      "currently at rank: 19, analyzing 2 nodes. Remaining size taxonomy: 1\n",
      "currently at rank: 20, analyzing 1 nodes. Remaining size taxonomy: 0\n"
     ]
    }
   ],
   "source": [
    "# The main research task requires determining the taxonomy rank.\n",
    "\n",
    "tax = rdflib.Graph()\n",
    "tax.parse(\"./data/tax_NCIT.ttl\") # only load in the taxonomy, as that is the only information relevant for this task.\n",
    "\n",
    "# initialize a dataframe keeping track of how many triples are present at each rank within the ontology\n",
    "rank_overview = pd.DataFrame(columns=['rank', 'count', 'tax_remaining'])\n",
    "node_set = {'http://www.w3.org/2002/07/owl#Thing'} # initialize the set with the top node of the ontology\n",
    "rank = 0 # Initialize the current rank to be 0\n",
    "while (len(node_set) != 0 ):\n",
    "    print(f'currently at rank: {rank}, analyzing {len(node_set)} nodes. Remaining size taxonomy: {len(tax)}')\n",
    "    triples_at_rank = []\n",
    "    for o in node_set: # for all nodes in the current node list, query which subclasses it has. The inheritance structure is maintained by storing the entire triple.\n",
    "        triples = list(tax.query(\n",
    "        f'CONSTRUCT {{?s <http://www.w3.org/2000/01/rdf-schema#subClassOf> <{o}>}} WHERE {{ ?s <http://www.w3.org/2000/01/rdf-schema#subClassOf> <{o}>. }}'\n",
    "        ))\n",
    "        triples_at_rank += triples # add all found triples to a list\n",
    "    df = pd.DataFrame(triples_at_rank, columns=['s','p','o']) # create pandas dataframe of the triple list\n",
    "    file_dir = './data/taxonomy_rank_trip_store/'\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "    df.to_csv(f'./data/taxonomy_rank_trip_store/rank_{rank+1}_to_{rank}.csv', sep=',', index=False)\n",
    "    rank_overview = pd.concat([rank_overview, pd.DataFrame(data={'rank':[rank+1], 'count':[len(df)], 'tax_remaining':[len(tax)]})]) # keep track of some statistics for easier validation\n",
    "    rank += 1\n",
    "    node_set = {t[0] for t in triples_at_rank} # create new node set based on the subject of all stored triples within triples_at_rank\n",
    "    for t in triples_at_rank: # remove the checked triples to prevent loops\n",
    "        tax.remove(t)\n",
    "\n",
    "file_dir = './data/taxonomy_ranks/'\n",
    "if not os.path.exists(file_dir):\n",
    "    os.makedirs(file_dir)\n",
    "rank_overview.to_csv(f'./data/taxonomy_ranks/rank_overview.csv', sep=',', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-11T17:24:12.303016Z",
     "end_time": "2023-04-11T17:38:46.373329Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function for inducing changes at ranks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def change_tax(tax, rank, p, enforce_change = True, rand_seed = 42):\n",
    "    \"\"\"\n",
    "    Function for determining the changes that are to be made to the taxonomy.\n",
    "    :param tax: the taxonomy that is to be changed\n",
    "    :param rank: The rank to which the changes should be applied\n",
    "    :param p: The probability that a subclass relation is changed\n",
    "    :param enforce_change: Enforce that the intended actually make a change (removes the current object from the set of possible new options)\n",
    "    :param rand_seed: Set the seed of the sampler\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(rand_seed) # Setting the seed of reproducibility\n",
    "\n",
    "    # Load the set of triples that can be changed\n",
    "    trips = pd.read_csv(f'./data/taxonomy_rank_trip_store/rank_{rank}_to_{rank-1}.csv', sep=',')\n",
    "\n",
    "    # Load the set of unique 'object' entities. This is used for determining the new object\n",
    "    unique_o_nodes = set(trips['o'])\n",
    "\n",
    "    # Sample a random subset from the selected triples. These are the triples that will be changed\n",
    "    mod_trips = trips.sample(frac=p, random_state=random.randint(0, 2**32 - 1))\n",
    "\n",
    "    # Rename the 'o(bject)' column to 'old_o(bject)'\n",
    "    mod_trips.rename(columns={'o':'old_o'}, inplace=True)\n",
    "\n",
    "    # Create a new column 'new_o(bject)' where the newly selected object is stored\n",
    "    mod_trips['new_o'] = [pick_alternative_o(unique_o_nodes.copy(), o, enforce_change) for o in mod_trips['old_o']]\n",
    "\n",
    "    # Update the taxonomy with the selected changes.\n",
    "    update_tax(tax, mod_trips, enforce_change)\n",
    "\n",
    "    # Write the selected changes into a change log for reproducibility\n",
    "    file_dir = f'./data/change_log/rank_{rank}_to_{rank-1}/'\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "    mod_trips.to_csv(file_dir+f'{p}.csv', sep=',', index=False)\n",
    "\n",
    "    print(f\"Total number of changes between rank {rank} and {rank-1}: {len(mod_trips)}\")\n",
    "\n",
    "\n",
    "\n",
    "def pick_alternative_o(options, current, enforce_change):\n",
    "    \"\"\"\n",
    "    Selects a random alternative object from a given set\n",
    "\n",
    "    :param options: The set of possible options\n",
    "    :param current: The current object\n",
    "    :param enforce_change: If true, remove the current object from the options set\n",
    "    :return: A valid alternative object\n",
    "    \"\"\"\n",
    "\n",
    "    # If we need to ensure the new ontology is different from the old one, remove the current 'object' from the set of possible objects.\n",
    "    if enforce_change:\n",
    "        options.remove(current)\n",
    "    return random.sample(list(options), 1)[0] # Sample a new object.\n",
    "\n",
    "\n",
    "def update_tax(tax, changes, enforce_change):\n",
    "    \"\"\"\n",
    "    Function for making adjustments to taxonomy\n",
    "    :param tax: The taxonomy that is to be altered\n",
    "    :param changes: Pandas Dataframe containing the columns ['s', 'p', 'old_o', 'new_o']\n",
    "    :param enforce_change: if true, the changes are guaranteed to make an actual change to the ontology\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop over all provided changes\n",
    "    for index, t in changes.iterrows():\n",
    "        if enforce_change: # If the change should result in a different ontology, perform additional checks.\n",
    "            contains_trip = list(tax.query( # Query for determining if the new triple is already present within the ontology\n",
    "                f'ASK {{ <{t.s}> <{t.p}> <{t.new_o}>}}'\n",
    "            ))[0]\n",
    "            if contains_trip: # If it returns true, something is wrong and this should be fixed\n",
    "                print(f'{t.old_o}, {t.new_o}')\n",
    "                changes.loc[index, 'New_triple_already_exists'] = 1\n",
    "            else:\n",
    "                changes.loc[index, 'New_triple_already_exists'] = 0\n",
    "\n",
    "        tax.add((URIRef(t.s), URIRef(t.p), URIRef(t.new_o))) # add the new triple to the ontology\n",
    "        tax.remove((URIRef(t.s), URIRef(t.p), URIRef(t.old_o))) # remove the old one\n",
    "\n",
    "    if enforce_change:\n",
    "        print(f'{sum(changes[\"New_triple_already_exists\"])} modified triplets were already present within the taxonomy')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T18:09:03.571625Z",
     "end_time": "2023-04-10T18:09:03.573803Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 2 and 1: 78\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 3 and 2: 1320\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 4 and 3: 2454\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 5 and 4: 3988\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 6 and 5: 3221\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 7 and 6: 2439\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 8 and 7: 2334\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 9 and 8: 3164\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 10 and 9: 974\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 11 and 10: 408\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 12 and 11: 130\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 13 and 12: 24\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 14 and 13: 4\n",
      "0.0 modified triplets were already present within the taxonomy\n",
      "Total number of changes between rank 15 and 14: 2\n"
     ]
    }
   ],
   "source": [
    "change_ratio = 0.1\n",
    "rand_seed = 42\n",
    "graph_name = 'tax_NCIT'\n",
    "\n",
    "tax = rdflib.Graph()\n",
    "tax.parse(f'./data/{graph_name}.ttl')\n",
    "\n",
    "# This loop will make modifications the subclass relation between entities with rank 2 to 1, 3 to 2, ect. all the way to rank 15 to 14\n",
    "for rank in range(2, 16):\n",
    "    tax_copy = copy.deepcopy(tax) # create a deep copy to make sure changes in higher ranks are not included in the new graph.\n",
    "    change_tax(tax_copy, rank, change_ratio, rand_seed=rand_seed)\n",
    "    file_dir = f'./data/modified_graphs/{graph_name}/rank_{rank}_to_{rank-1}/'\n",
    "    if not os.path.exists(file_dir):\n",
    "        os.makedirs(file_dir)\n",
    "    file_name = file_dir+f'{change_ratio}.ttl'\n",
    "    tax_copy.serialize(file_name, format='ttl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-10T18:09:03.576688Z",
     "end_time": "2023-04-10T18:16:36.535085Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
